#!/usr/bin/env ruby
require 'selenium-webdriver'
require 'nokogiri'
require 'uri'
require 'natto' # MeCab ãƒã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆgem 'natto' ã‚’ä½¿ç”¨ï¼‰

# Chrome (ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹) ã‚’èµ·å‹•
def create_driver
  opts = Selenium::WebDriver::Chrome::Options.new
  opts.add_argument('--headless=new') rescue opts.add_argument('--headless')
  opts.add_argument('--no-sandbox')
  opts.add_argument('--disable-dev-shm-usage')
  opts.add_argument('--disable-blink-features=AutomationControlled')
  opts.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
  Selenium::WebDriver.for(:chrome, options: opts)
end

def fetch_search_urls(keyword, driver)
  # DuckDuckGo HTMLç‰ˆï¼ˆbotå¯¾ç­–ãŒç·©ã„ï¼‰
  search_url = "https://html.duckduckgo.com/html/?q=#{URI.encode_www_form_component(keyword)}"
  driver.navigate.to(search_url)

  sleep 2 # ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿å¾…ã¡

  doc = Nokogiri::HTML(driver.page_source)
  urls = []
  
  # HTMLç‰ˆã®ã‚»ãƒ¬ã‚¯ã‚¿
  doc.css('a.result__a').each do |a|
    href = a['href']
    next unless href
    
    # DuckDuckGoã®ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆURLã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
    if href =~ /uddg=([^&]+)/
      url = URI.decode_www_form_component($1)
      urls << url
    elsif href.start_with?('http')
      urls << href
    end
  end

  urls.compact.uniq.first(3)
end

def fetch_page_text(url, driver)
  driver.navigate.to(url)
  # ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿å®Œäº†å¾…ã¡
  wait = Selenium::WebDriver::Wait.new(timeout: 8)
  begin
    wait.until { driver.execute_script('return document.readyState') == 'complete' }
  rescue Selenium::WebDriver::Error::TimeoutError
    # ç¶šè¡Œ
  end

  doc = Nokogiri::HTML(driver.page_source)
  doc.search('script, style, noscript').remove
  text = doc.text.gsub(/\s+/, ' ').strip
  text
end

def extract_words_with_mecab(text)
  nm = Natto::MeCab.new
  words = []
  nm.parse(text) do |n|
    break if n.is_eos?
    features = n.feature.split(',')
    # åè©ã‚’æŠ½å‡ºï¼ˆä»–ã®æ¡ä»¶ã«å¤‰ãˆã‚‹ã“ã¨ã‚‚å¯ï¼‰
    words << n.surface if features[0] == 'åè©' && n.surface && n.surface.strip != ''
  end
  words
end

def filter_keywords(words)
  words.reject do |word|
    # æ•°å­—ã ã‘ã€è¨˜å·ã ã‘ã€1æ–‡å­—ã ã‘ã‚’é™¤å¤–
    word.match?(/^[\d:\/\(\)\.\-\!\&\Â°]+$/) || word.length == 1
  end
end

driver = create_driver

begin
  puts "ğŸ” æ¤œç´¢ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:"
  keyword = STDIN.gets&.strip.to_s

  puts "\nğŸŒ ä¸Šä½3ä»¶ã®URLã‚’å–å¾—ã—ã¾ã—ãŸ:"
  urls = fetch_search_urls(keyword, driver)
  
  if urls.empty?
    puts "âš ï¸ URLãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"
    exit
  end
  
  urls.each_with_index { |u, i| puts "#{i+1}: #{u}" }

  puts "\nğŸ“ˆ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰åˆ†æã‚’é–‹å§‹ã—ã¾ã™..."
  all_text = ''

  urls.each do |url|
    print "â–¶ #{url} ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºä¸­... "
    begin
      text = fetch_page_text(url, driver)
      if text.empty?
        puts "âš ï¸ ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™"
      else
        all_text << text << ' '
        puts "å®Œäº† (#{text.length}æ–‡å­—)"
      end
    rescue => e
      puts "âš ï¸ å–å¾—ã«å¤±æ•—: #{e.class}: #{e.message}"
    end
  end

  if all_text.strip.empty?
    puts "\nå–å¾—ã—ãŸãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™ã€‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚"
    exit
  end

  # MeCabã§åè©ã‚’æŠ½å‡ºã—ã¦é »åº¦ã‚«ã‚¦ãƒ³ãƒˆ
  words = extract_words_with_mecab(all_text)
  words = filter_keywords(words) # ãƒã‚¤ã‚ºé™¤å»
  freq = words.each_with_object(Hash.new(0)) { |w, h| h[w] += 1 }

  top300 = freq.sort_by { |_, v| -v }.first(300)

  puts "\nğŸ“ˆ é »å‡ºã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆä¸Šä½300ãƒ»ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æ¸ˆã¿ï¼‰"
  top300.each_with_index do |(word, count), i|
    puts "#{i+1}. #{word} - #{count}å›"
  end
  
  puts "\nâœ… åˆ†æå®Œäº†ï¼"
ensure
  driver.quit rescue nil
end
